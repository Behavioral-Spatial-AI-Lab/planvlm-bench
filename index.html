<!DOCTYPE html>
<html>
<head>
  <title>PlanVLM-bench</title>
  <meta charset="utf-8">
  <meta name="description"
        content="Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models">
  <meta name="keywords" content="PlanVLM-bench, LVLM, LVLM Evaluation, multiple images, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PlanVLM-bench: Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="stylesheet" href="./css/leaderboard.css">

  <style>
    .hidden {
      display: none;
    }
  </style>
</head>

<body>
<div id="language-switcher" style="position: absolute; top: 1rem; left: 1rem; z-index: 999;">
  <button onclick="changeLanguage('en')" 
          class="external-link button is-normal is-rounded is-dark" 
          style="margin-right: 0.5rem;">
    English
  </button>
  <button onclick="changeLanguage('zh')" 
          class="external-link button is-normal is-rounded is-dark">
    ä¸­æ–‡
  </button>
</div>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: flex-end;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com">
            <b>PlanVLM</b> <p style="font-size:18px; display: inline; margin-left: 5px;">ğŸ”¥</p>
          </a>
          <a class="navbar-item" href="https://github.com">
            <b>PlanGPT-Bench</b> <p style="font-size:18px; display: inline; margin-left: 5px;">ğŸ”¥</p>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <span class="MMIU" style="vertical-align: middle">PlanVLM-bench</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Minxin Chen<sup>â€ ,</sup><sup style="color:#6fbf73;">1,</sup><sup style="color:#ffac33;">2</sup></a>
              ,
            </span>
            <span class="author-block">
              He Zhu<sup>â€ ,</sup><sup style="color:#6fbf73;">1,</sup><sup style="color:#ffac33;">2</sup></a>
              ,
            </span>
            <span class="author-block">
              Junyou Su</sup><sup style="color:#6fbf73;">1,</sup><sup style="color:#ffac33;">2</sup></a>
              ,
            </span>
            <span class="author-block">
              Wen Wang</sup><sup style="color:#6fbf73;">1,</sup><sup style="color:#ffac33;">2</sup></a>
              ,
            </span>
            <span class="author-block">
              Yijie Deng</sup><sup style="color:#6fbf73;">1,</sup><sup style="color:#ffac33;">2</sup></a>
              ,
            </span>
            <span class="author-block">
              Wenjia Zhang<sup>*,</sup><sup style="color:#6fbf73;">1,</sup><sup style="color:#ed4b82;">3</sup></a>
            </span>
<!--             <span class="author-block">Quanfeng Lu<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Hao Tian<sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Jiaqi Liao<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Xizhou Zhu<sup style="color:#9b51e0;">5</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Jifeng Dai<sup style="color:#9b51e0;">5</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Yu Qiao<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">
              Ping Luo<sup style="color:#ed4b82;">3</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
-->
          
          </div>
          
          <br>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>Behavioral and Spatial AI Lab, Tongji University</span>
            <span class="author-block"><sup style="color:#ffac33;">2</sup>Behavioral and Spatial AI Lab, Peking University</span>
            <span class="author-block"><sup style="color:#ed4b82;">3</sup>College of Architecture and Urban Planning, Tongji University</span>
            <!-- <span class="author-block"><sup style="color:#007bff;">4</sup>SenseTime Research,</span>
            <span class="author-block"><sup style="color:#9b51e0;">5</sup>Tsinghua University</span> --> 
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Corresponding Author:</span>
            <span class="author-block"><a href="mailto:zhangkaipeng@pjlab.org.cn">wenjiazhang@tongji.edu.cn</a></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">â€ Equal Contribution</span>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ğŸ¤—</p>
                      <!-- ğŸ”— -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Leaderboard Link. -->
              <!-- <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-trophy"></i>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ””News</h2>
        <div class="content has-text-justified">
          <p style="color: red>
            <b>[2025-05-20] The arxiv article and dataset along with the code will be launched soon.</a>.</b>
          </p>
      </div>      
        <div class="lang-en">
            <h2 class="title is-3">Introduction</h2>
            <div class="content has-text-justified">
            <p  style="line-height: 2;">
                Planning maps of territorial and spatial planning visually present the concepts, objectives, strategies, and specific measures of territorial and spatial planning in map form, serving to guide and coordinate various development, protection, and utilization activities across territorial space. They not only constitute a critical basis for planning decisions but also act as essential tools for public participation and oversight of plan implementation. Given the complexity and specialized nature of planning work, fully grasping planning maps requires not only grasping fine-grained elements (such as symbols, legends, and geographic features) but also possessing the ability to perform comprehensive analysis and judgment in conjunction with relevant policies. This complexity renders the interpretation of planning maps particularly challenging.With the rapid advancement of multimodal large language models (MLLMs), we have established a benchmark for territorial and spatial planning maps to assess MLLMsâ€™ map-understanding capabilities. Our contributions are as follows:<br> 
                <br>
                <b>(1)	Data:</b> We constructed the Spatial Planning Map Database (SPMD), an expert-annotated repository characterized by diverse map content and high-quality annotations provided by planning domain specialists.<br> 
                <b>(2)	Framework:</b> We proposed a comprehensive, planning-disciplineâ€“based evaluation standard that measures MLLMsâ€™ planning-map comprehension from four perspectivesâ€”perception, reasoning, association, and applicationâ€”comprising eight fine-grained subcategories.<br> 
                <b>(3)	Experiments:</b> By designing questionâ€“answer tasks grounded in authoritative question banks (specifically, the practice exam questions for the Chinese Registered Urban Planner qualification), we significantly reduced the incidence of hallucinated normative references by the models.<br> 
                <b>(4)	Results:</b> Current state-of-the-art visual large models exhibit significant limitations in the tasks of interpreting and analyzing planning maps. Specifically, these models often fail to accurately recognize the various elements within planning maps and lack the policy-sensitive acuity and professional analytical skills required for planning practice.<br> 
            </p>
            </div>
        </div>
        <div class="lang-zh" style="display: none;">
            <h2 class="title is-3">æ¦‚è¿°</h2>
            <div class="content has-text-justified" style="line-height: 2;">
            <p>
                å›½åœŸç©ºé—´è§„åˆ’å›¾æ˜¯å°†å›½åœŸç©ºé—´è§„åˆ’çš„ç†å¿µã€ç›®æ ‡ã€ç­–ç•¥å’Œå…·ä½“æªæ–½ä»¥åœ°å›¾çš„å½¢å¼ç›´è§‚å±•ç¤ºå‡ºæ¥ï¼Œç”¨äºæŒ‡å¯¼å’Œåè°ƒå„ç±»å›½åœŸç©ºé—´å¼€å‘ã€ä¿æŠ¤å’Œåˆ©ç”¨æ´»åŠ¨ã€‚å®ƒä¸ä»…æ˜¯è§„åˆ’å†³ç­–çš„é‡è¦ä¾æ®ï¼Œä¹Ÿæ˜¯å…¬ä¼—å‚ä¸å’Œç›‘ç£è§„åˆ’å®æ–½çš„é‡è¦å·¥å…·ã€‚è§„åˆ’æ˜¯ç»¼åˆæ€§å’Œä¸“ä¸šæ€§æå¼ºçš„å·¥ä½œï¼Œå¦‚æœè¦è¯»é€è§„åˆ’å›¾çº¸ï¼Œä¸ä»…è¦æŠ“ä½ç²¾ç»†çš„å…ƒç´ ï¼ˆç¬¦å·ã€å›¾ä¾‹å’Œåœ°ç†è¦ç´ ç­‰ï¼‰ï¼Œè¿˜è¦æœ‰ç»“åˆæ”¿ç­–è¿›è¡Œç»¼åˆåˆ†æå’Œåˆ¤æ–­çš„èƒ½åŠ›ã€‚è¿™ç§å¤æ‚æ€§ä½¿å¾—è§„åˆ’å›¾çš„ç†è§£å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éšç€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæˆ‘ä»¬å»ºç«‹äº†å›½åœŸç©ºé—´è§„åˆ’å›¾çš„Benchmarkï¼Œä»¥è¯„ä¼°MLLMsåœ¨è§„åˆ’å›¾ç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„è´¡çŒ®å¦‚ä¸‹ï¼š<br>
                <b>(1)	æ•°æ®ï¼š</b> æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¸“å®¶æ ‡æ³¨çš„è§„åˆ’å›¾æ•°æ®åº“Spatial Planning Map Databaseï¼ˆSPMD)ï¼Œå…¶ç‰¹ç‚¹æ˜¯å¤šæ ·åŒ–çš„å›¾åƒå†…å®¹å’Œç”±è§„åˆ’é¢†åŸŸä¸“å®¶æä¾›çš„é«˜è´¨é‡æ ‡æ³¨ã€‚<br>
                <b>(2)	æ¡†æ¶ï¼š</b> æˆ‘ä»¬æå‡ºäº†ä¸€å¥—åŸºäºè§„åˆ’å­¦ç§‘çš„ç»¼åˆæ ‡å‡†ï¼Œä»æ„ŸçŸ¥ã€æ¨ç†ã€å…³è”ã€åº”ç”¨å››ä¸ªè§’åº¦è¡¡é‡MLLMsçš„è§„åˆ’å›¾ç†è§£èƒ½åŠ›ï¼ŒåŒ…æ‹¬8ä¸ªç»†åˆ†ç±»åˆ«ã€‚<br>
                <b>(3)	å®éªŒï¼š</b> é€šè¿‡åŸºäºæƒå¨é¢˜åº“ï¼ˆä¸­å›½æ³¨å†ŒåŸå¸‚è§„åˆ’å¸ˆæ‰§ä¸šèµ„æ ¼è€ƒè¯•å®åŠ¡é¢˜ç›®ï¼‰çŸ¥è¯†æ„å»ºçš„é—®ç­”ä»»åŠ¡ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹â€œå¹»è§‰å¼è§„èŒƒå¼•ç”¨â€çš„æ¯”ä¾‹ã€‚<br>
                <b>(4)	ç»“æœï¼š</b> ç›®å‰çš„SOTAè§†è§‰å¤§æ¨¡å‹ï¼Œåœ¨è§£è¯»å’Œåˆ†æè§„åˆ’å›¾ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„å±€é™æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œè¿™äº›æ¨¡å‹å¸¸å¸¸æ— æ³•å®Œå…¨å‡†ç¡®è¯†åˆ«è§„åˆ’å›¾ä¸­çš„å„ç±»è¦ç´ ï¼Œä¹Ÿç¼ºä¹è§„åˆ’æ‰€éœ€çš„æ”¿ç­–å—…è§‰çµæ•åº¦å’Œä¸“ä¸šåˆ†æèƒ½åŠ›ã€‚<br>
            </p>
            </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 MMIU">
    <span class="MMIU" style="vertical-align: middle">MMIU</span>
  </h1>
  </div>
</section> -->

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="./pictures/VLMbench250512.png" alt="pipeline" class="center">
        </div>
        <div class="lang-en">
          <div class="content has-text-justified" style="line-height: 2;">
            <p>
              We propose a conceptual framework tailored to the domain of urban planning visualization.This framework comprises the following 4 dimensions and 8 categories:
              <h3 class="title is-5">Perception</h3>
              The questions of the perception subset consist of 2 categories as follows:<br>
              <b>Element Recognition</b> evaluates models' ability to identify layout configurations, textual annotations, basic geographic features, and drawing elements in planning maps. It facilitates the establishment of semantic alignment between image content and natural language.<br>
              <!-- <img src="./pictures/table1.png" alt="table1" class="center"> -->
              <b>Caption</b>ï¼Œin this study, refers to extracting as many details from the image as possible. The model generates descriptions based solely on the image itself, rather than identifying elements in response to a specific question. The quality of the caption reflects whether the model has truly "seen" the image clearly.<br>
              Example Question: "Please describe this planning map in detail."
              <h3 class="title is-5">Reasoning</h3>
              This dimension encompasses classification, spatialâ€relation reasoning, and domainâ€specific reasoning. <br>
              <b>Classification</b> focuses on the ability to recognize different types of planning maps. Based on China's five-level, three-category planning system, the maps are categorized into master plans, detailed plans (including regulatory and site plans), and specialized planning maps.<br>
              <b>Spatial Relationship Reasoning</b>, as shown in Table 2, assesses the understanding of spatial relationships between geographic elements in planning maps, including: topological spatial relations, sequential spatial relations, and metric spatial relations.<br>
              <!-- <img src="./pictures/table2.png" alt="table2" class="center"> -->
              <b>Professional Reasoning</b>, which measures mastery of planning knowledge such as layout morphology, functional organization, transportation systems, and environmental ecology, distinct from general logical inference.
              <h3 class="title is-5">Association</h3>
              This dimension assesses the ability to collect and relate background policies and contextual documents relevant to planning maps. At a fine scale, it examines policy, regulations, and planning indicators.
              <h3 class="title is-5">Implementation</h3>
              This dimension addresses the capacity for comparing, critiquing, and optimizing planning proposals. Given the highly integrative and wideâ€ranging nature of urban planning, the ability to identify critical issues and emphasize key priorities is paramount.<br>
              The questions of the Implementation subset consist of 3 categories as follows:<br>
              <b>Task Abstraction:</b> This assesses the ability to identify and extract key information from the question text. In the Certified Urban-Rural Planner Qualification Examination, practical questions often include a long background passage containing irrelevant constraints that need to be filtered and summarized.<br>
              <blockquote>
                Example Question: â€œA county currently has a population of 980,000, including 520,000 urban residents. By 2035, the plan aims to increase the urbanization rate to 80%. Three central townsâ€”A, B, and Câ€”and the old district of the county seat will undergo upgrading and renovation. Sixty percent of the population will be relocated to newly built residential areas on the outskirts of the county seat. The plan also includes the development of a food industrial park and rural tourism, as shown in the figure. What are the main issues presented in the map? Please extract the key information from the question.â€
                <br>
                Example Answer: The key points in this question are urbanization rate, central town, population migration, and food industrial park.
              </blockquote>

              <b>Task-Oriented Image Summarization</b> assesses the ability to identify and extract key information from an image. The image often contains rich information, and some parts are highly relevant to the correct answer and need to be summarized accordingly.<br>
              
              <blockquote>
                Example Question: â€œIdentify the main issues shown in the image.â€<br>
                Example Answer: â€œThe main issues in the image include the spatial relationship between Central Town A, the food industrial park, and the floodplain; the topological relationship between the expressway and the nationally protected wetland; the distance between the planned interchange on the west side of the expressway and the existing one; and the overall distribution of central towns.â€<br>
              </blockquote>
              </p>
          </div>
        </div>
        <div class="lang-zh" style="display: none;">
          <div class="content has-text-justified" style="line-height: 2;">
            <p>
              æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å›½åœŸç©ºé—´è§„åˆ’å¯è§†åŒ–é¢†åŸŸçš„æ¦‚å¿µæ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹4ä¸ªç»´åº¦å’Œ8ä¸ªç±»åˆ«ï¼š
              <h3 class="title is-5">æ„ŸçŸ¥</h3>
              æ„ŸçŸ¥ç»´åº¦ä¸­çš„é—®é¢˜åŒ…æ‹¬ä»¥ä¸‹2ä¸ªç±»åˆ«ï¼š<br>
              <b>å…ƒç´ è¯†åˆ«</b>è¯„ä¼°æ¨¡å‹å¯¹è§„åˆ’å›¾ä¸Šå›¾å¹…é…ç½®ã€æ–‡å­—ã€åŸºç¡€åœ°ç†è¦ç´ ã€å›¾çº¸è¦ç´ çš„è¯†åˆ«èƒ½åŠ›ã€‚å®ƒæœ‰åŠ©äºæ¨¡å‹å»ºç«‹å›¾åƒå†…å®¹ä¸è‡ªç„¶è¯­è¨€ä¹‹é—´çš„è¯­ä¹‰æ˜ å°„ã€‚<br>
              <!-- <img src="./pictures/table1.png" alt="table1" class="center"> -->
              <b>æè¿°</b>ï¼Œåœ¨æœ¬ç ”ç©¶ä¸­æŒ‡æ‰’å‡ºå›¾åƒä¸­å°½å¯èƒ½å¤šçš„ç»†èŠ‚ã€‚æ¨¡å‹ä»…åŸºäºå›¾åƒæœ¬èº«ï¼Œè€Œä¸æ˜¯åŸºäºé—®é¢˜å»ä»å›¾ä¸­å®šä½è¦ç´ ã€‚Caption çš„è´¨é‡å¯ä»¥åæ˜ æ¨¡å‹æ˜¯å¦çœŸæ­£â€œçœ‹æ¸…â€äº†å›¾åƒã€‚<br>
              ç¤ºä¾‹é—®é¢˜ï¼šâ€œè¯·è¯¦ç»†æè¿°è¿™å¼ è§„åˆ’å›¾ã€‚â€
              <h3 class="title is-5">æ¨ç†</h3>
              è¿™ä¸ªç»´åº¦åŒ…æ‹¬åˆ†ç±»ã€ç©ºé—´å…³ç³»æ¨ç†å’Œä¸“ä¸šæ¨ç†ã€‚<br>
              <b>åˆ†ç±»</b>å…³æ³¨æ¨¡å‹å¯¹ä¸åŒç±»å‹çš„è§„åˆ’å›¾çš„è¯†åˆ«èƒ½åŠ›ã€‚ç›®å‰æŒ‰ä¸­å›½çš„äº”çº§ä¸‰ç±»ä½“ç³»ï¼Œåˆ†ä¸ºæ€»ä½“è§„åˆ’ï¼Œè¯¦ç»†è§„åˆ’ï¼ˆæ§åˆ¶æ€§ã€ä¿®å»ºæ€§ï¼‰å’Œä¸“é¡¹è§„åˆ’å›¾ã€‚<br>
              <b>ç©ºé—´å…³ç³»æ¨ç†</b>ï¼Œè¯„ä¼°è§„åˆ’å›¾ä¸­åœ°ç†å…ƒç´ ä¹‹é—´çš„ç©ºé—´å…³ç³»ç†è§£ï¼ŒåŒ…æ‹¬ï¼šæ‹“æ‰‘ç©ºé—´å…³ç³»ã€é¡ºåºç©ºé—´å…³ç³»å’Œåº¦é‡ç©ºé—´å…³ç³»ã€‚<br>
              <!-- <img src="./pictures/table2.png" alt="table2" class="center"> -->
              <b>ä¸“ä¸šæ¨ç†</b>ï¼Œè€ƒå¯Ÿè§„åˆ’å›¾ä¸“ä¸šçŸ¥è¯†æŒæ¡çš„èƒ½åŠ›ã€‚åŒ…æ‹¬å¸ƒå±€å½¢æ€ã€åŠŸèƒ½ç»„ç»‡ã€äº¤é€šä½“ç³»ã€ ç¯å¢ƒç”Ÿæ€ç­‰ï¼ŒåŒºåˆ«äºå¸¸è§„é€»è¾‘æ¨æ–­ã€‚
              <h3 class="title is-5">å…³è”</h3>
              è¯¥ç»´åº¦è¯„ä¼°æ”¶é›†è¿‡ç¨‹ä¸­æŒ‡ä¸è§„åˆ’å›¾ç›¸å…³çš„èƒŒæ™¯æ”¿ç­–ã€æ–‡ä»¶ä¸Šä¸‹æ–‡çš„é—®é¢˜ã€‚å°å°ºåº¦æ³¨è§„çœŸé¢˜ï¼šæ”¿ç­–ã€è§„èŒƒã€è§„åˆ’æŒ‡æ ‡ã€‚
              <h3 class="title is-5">åº”ç”¨</h3>
              è¯¥ç»´åº¦æ¶‰åŠæ¯”è¾ƒã€æ‰¹è¯„å’Œä¼˜åŒ–è§„åˆ’æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚ç”±äºåŸå¸‚è§„åˆ’çš„é«˜åº¦ç»¼åˆæ€§å’Œå¹¿æ³›æ€§ï¼Œè¯†åˆ«å…³é”®é—®é¢˜å’Œå¼ºè°ƒé‡ç‚¹ä¼˜å…ˆäº‹é¡¹çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚
              åº”ç”¨ç»´åº¦ä¸­çš„é—®é¢˜åŒ…æ‹¬ä»¥ä¸‹3ä¸ªç±»åˆ«ï¼š<br>
              <b>é¢˜ç›®å½’çº³</b> è€ƒå¯Ÿè¯†åˆ«å½’çº³æå–é¢˜ç›®æ–‡æœ¬é‡ç‚¹çš„èƒ½åŠ›ã€‚æ³¨å†Œè§„åˆ’å¸ˆå®åŠ¡è€ƒè¯•é¢˜ç›®é€šå¸¸ä¼šæä¾›ä¸€æ®µèƒŒæ™¯ä¿¡æ¯çš„é•¿æ–‡æœ¬ï¼Œæœ‰ä¸€äº›å’Œç­”æ¡ˆæ— å…³çš„çº¦æŸæ¡ä»¶ï¼Œéœ€è¦è¿›è¡Œè¿‡æ»¤å’Œå½’çº³ã€‚<br>
              <blockquote>
                ç¤ºä¾‹é—®é¢˜ï¼šâ€œä¸€ä¸ªå¿ç›®å‰æœ‰98ä¸‡äººå£ï¼Œå…¶ä¸­52ä¸‡äººä¸ºåŸå¸‚å±…æ°‘ã€‚åˆ°2035å¹´ï¼Œè®¡åˆ’å°†åŸå¸‚åŒ–ç‡æé«˜åˆ°80%ã€‚ä¸‰ä¸ªä¸­å¿ƒåŸé•‡Aã€Bå’ŒCä»¥åŠå¿åŸçš„æ—§åŒºå°†è¿›è¡Œå‡çº§å’Œæ”¹é€ ã€‚60%çš„äººå£å°†è¿ç§»åˆ°å¿åŸéƒŠåŒºæ–°å»ºçš„ä½å®…åŒºã€‚è¯¥è®¡åˆ’è¿˜åŒ…æ‹¬å»ºè®¾é£Ÿå“å·¥ä¸šå›­åŒºå’Œä¹¡æ‘æ—…æ¸¸ï¼Œå¦‚å›¾æ‰€ç¤ºã€‚å›¾ä¸­ä¸»è¦é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿè¯·æå–é—®é¢˜ä¸­çš„å…³é”®ä¿¡æ¯ã€‚â€
                <br>
                ç¤ºä¾‹ç­”æ¡ˆï¼šè¿™ä¸ªé—®é¢˜çš„å…³é”®ç‚¹æ˜¯åŸå¸‚åŒ–ç‡ã€ä¸­å¿ƒåŸé•‡ã€äººå£è¿ç§»å’Œé£Ÿå“å·¥ä¸šå›­åŒºã€‚
              </blockquote>
              <b>é¢˜å›¾å½’çº³</b>è€ƒå¯Ÿè¯†åˆ«å½’çº³æå–å›¾ä¸­é‡ç‚¹çš„èƒ½åŠ›,å›¾ä¸­æ‰¿è½½ç€ä¸°å¯Œçš„ä¿¡æ¯ï¼Œæœ‰ä¸€äº›å’Œç­”æ¡ˆå¼ºç›¸å…³çš„éƒ¨åˆ†ï¼Œéœ€è¦è¿›è¡Œå½’çº³ã€‚<br>
              <blockquote>
                ç¤ºä¾‹é—®é¢˜ï¼šâ€œæå–å›¾ç‰‡ä¸­å­˜åœ¨çš„ä¸»è¦é—®é¢˜ã€‚â€<br>
                ç¤ºä¾‹ç­”æ¡ˆï¼šâ€œå›¾ç‰‡ä¸­çš„ä¸»è¦é—®é¢˜æ˜¯ä¸­å¿ƒé•‡Aã€é£Ÿå“äº§ä¸šå›­ä¸æ²³å ¤è¡Œæ´ªçš„å…³ç³»ï¼›é«˜é€Ÿå…¬è·¯ä¸å›½å®¶é‡è¦æ¹¿åœ°çš„æ‹“æ‰‘å…³ç³»ï¼›è§„åˆ’é«˜é€Ÿè¥¿ä¾§ç«‹äº¤å£ä¸ç°çŠ¶é«˜é€Ÿç«‹äº¤å£çš„è·ç¦»ï¼›ä¸­å¿ƒé•‡åˆ†å¸ƒæƒ…å†µã€‚â€<br>
              </blockquote>
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Performance</h2>
        <div class="content has-text-justified">
          <img src="./pictures/radar_image.png" alt="radar_image" class="center">
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  .image-row {
      display: center; /* Use flexbox layout */
  }
  .image-row img {
      width: 40%; /* Each image takes up 50% of the width */
  }
</style>

<div class="container mt-6">
  <div class="content">
    <!-- è‹±æ–‡ç‰ˆï¼ˆé»˜è®¤æ˜¾ç¤ºï¼‰ -->
    <div class="lang-en">
      <h2 class="title is-4">Acknowledgements</h2>
      <p><strong>VQA Data Annotators:</strong> Siqi Zha, Yeyang Fu, Chuang Deng, Fenghong An, Hanying Li, Jiayi Fan</p>
      <p><strong>Internal Testers:</strong> Jialu Yu, Yingqi Guo</p>
      <br>
    </div>
    <!-- ä¸­æ–‡ç‰ˆï¼ˆé»˜è®¤éšè—ï¼‰ -->
    <div class="lang-zh" style="display: none;">
      <h2 class="title is-4">è‡´è°¢</h2>
      <p><strong>VQAæ•°æ®æ ‡æ³¨äººå‘˜ï¼š</strong>æŸ¥æ€é½ï¼Œä»˜å¶æ‰¬ï¼Œé‚“é—¯ï¼Œå®‰æ«æ³“ï¼Œæç€šæ»¢ï¼ŒèŒƒä½³æŒ¹</p>
      <p><strong>å†…æµ‹äººå‘˜ï¼š</strong>äºä½³ç’ï¼Œéƒ­ç‘›ç¦</p>
      <br>
    </div>
  </div>
</div>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <p style="color: red; font-weight: bold;">
          Note: This content is part of a manuscript under submission. Please do not cite until it is officially published. The arxiv article and dataset along with the code will be launched soon.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- @PAN TODO: bibtex -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @misc{meng2024mmiumultimodalmultiimageunderstanding,
        title={MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models}, 
        author={Fanqing Meng and Jin Wang and Chuanhao Li and Quanfeng Lu and Hao Tian and Jiaqi Liao and Xizhou Zhu and Jifeng Dai and Yu Qiao and Ping Luo and Kaipeng Zhang and Wenqi Shao},
        year={2024},
        eprint={2408.02718},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2408.02718}, 
  }
</code></pre>
  </div>
</section> -->

<!-- <footer class="footer">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://github.com/OpenGVLab/MMT-Bench">MMT-Bench</a>, <a href="https://mmmu-benchmark.github.io/">MMMU</a>, <a href="https://mathvista.github.io/">MathVista</a> and <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>

</footer> -->

<script>
    function changeLanguage(language) {
        // Hide all language-specific content
        var enContent = document.querySelectorAll('.lang-en');
        var zhContent = document.querySelectorAll('.lang-zh');
        
        if (language === 'en') {
            enContent.forEach(function (el) {
                el.style.display = 'block';
            });
            zhContent.forEach(function (el) {
                el.style.display = 'none';
            });
        } else if (language === 'zh') {
            zhContent.forEach(function (el) {
                el.style.display = 'block';
            });
            enContent.forEach(function (el) {
                el.style.display = 'none';
            });
        }
    }
</script>

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' â†‘';
  }
  .desc::after {
      content: ' â†“';
  }

  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }

  .publication-links .link-block {
    margin: 0 0.5rem;
    display: inline-block;
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* é¼ æ ‡æ‚¬åœæ—¶çš„é˜´å½±æ•ˆæœ */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>
</body>
</html>
