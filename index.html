<!DOCTYPE html>
<html>
<head>
  <title>PlanVLM-bench</title>
  <meta charset="utf-8">
  <meta name="description"
        content="Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models">
  <meta name="keywords" content="PlanVLM-bench, LVLM, LVLM Evaluation, multiple images, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PlanVLM-bench: Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="stylesheet" href="./css/leaderboard.css">

  <style>
    .hidden {
      display: none;
    }
  </style>
</head>

<body>
<div id="language-switcher" style="position: absolute; top: 1rem; left: 1rem; z-index: 999;">
  <button onclick="changeLanguage('en')" 
          class="external-link button is-normal is-rounded is-dark" 
          style="margin-right: 0.5rem;">
    English
  </button>
  <button onclick="changeLanguage('zh')" 
          class="external-link button is-normal is-rounded is-dark">
    ä¸­æ–‡
  </button>
</div>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: flex-end;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/OpenGVLab/Multi-Modality-Arena">
            <b>Lvlm-ehub</b> <p style="font-size:18px; display: inline; margin-left: 5px;">ğŸ”¥</p>
          </a>
          <a class="navbar-item" href="https://github.com/OpenGVLab/MMT-Bench">
            <b>MMT-Bench</b> <p style="font-size:18px; display: inline; margin-left: 5px;">ğŸ”¥</p>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <span class="MMIU" style="vertical-align: middle">PlanVLM-bench</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Fanqing Meng<sup>*,</sup><sup style="color:#ffac33;">2</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
            </span>
            <span class="author-block">
              Jin Wang<sup>*,</sup><sup style="color:#ed4b82;">3</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
            </span>
            <span class="author-block">
              Chuanhao Li<sup>*,</sup><sup style="color:#6fbf73;">1</sup></a>,
            </span>
            <span class="author-block">Quanfeng Lu<sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Hao Tian<sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Jiaqi Liao<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Xizhou Zhu<sup style="color:#9b51e0;">5</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup><sup>,</sup><sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Jifeng Dai<sup style="color:#9b51e0;">5</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">Yu Qiao<sup style="color:#6fbf73;">1</sup>,</span>
            <span class="author-block">
              Ping Luo<sup style="color:#ed4b82;">3</sup><sup>,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
          </span>
          <span class="author-block">
              Kaipeng Zhang<sup>â€ ,</sup><sup style="color:#6fbf73;">1</sup></a>
              ,
          </span>
          <span class="author-block">
              Wenqi Shao<sup>â€ ,</sup><sup style="color:#6fbf73;">1</sup></a>
              
          </span>
          
          </div>
          
          <br>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>OpenGVLab, Shanghai AI Laboratory,</span>
            <span class="author-block"><sup style="color:#ffac33;">2</sup>Shanghai Jiao Tong University,</span></br>
            <span class="author-block"><sup style="color:#ed4b82;">3</sup>The University of Hong Kong,</span>
            <span class="author-block"><sup style="color:#007bff;">4</sup>SenseTime Research,</span>
            <span class="author-block"><sup style="color:#9b51e0;">5</sup>Tsinghua University</span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution</span><br>
            <span class="author-block">â€ Corresponding Author:</span>
            <span class="author-block"><a href="mailto:shaowenqi@pjlab.org.cn">shaowenqi@pjlab.org.cn</a>,</span>
            <span class="author-block"><a href="mailto:zhangkaipeng@pjlab.org.cn">zhangkaipeng@pjlab.org.cn</a></span>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ğŸ¤—</p>
                      <!-- ğŸ”— -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Leaderboard Link. -->
              <!-- <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-trophy"></i>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">ğŸ””News</h2>
        <div class="content has-text-justified">
          <p>
            <b>ğŸ”¥[2024-08-07] We released the <a href="https://arxiv.org/abs/2408.02718">technical report</a>.</b>
          </p>
      </div>      
        <div class="lang-en">
            <h2 class="title is-3">Introduction</h2>
            <div class="content has-text-justified">
            <p>
                Planning maps of territorial and spatial planning visually present the concepts, objectives, strategies, and specific measures of territorial and spatial planning in map form, serving to guide and coordinate various development, protection, and utilization activities across territorial space. They not only constitute a critical basis for planning decisions but also act as essential tools for public participation and oversight of plan implementation. Given the complexity and specialized nature of planning work, fully grasping planning maps requires not only grasping fine-grained elements (such as symbols, legends, and geographic features) but also possessing the ability to perform comprehensive analysis and judgment in conjunction with relevant policies. This complexity renders the interpretation of planning maps particularly challenging.With the rapid advancement of multimodal large language models (MLLMs), we have established a benchmark for territorial and spatial planning maps to assess MLLMsâ€™ map-understanding capabilities. Our contributions are as follows:<br> 
                <b>(1)	Data:</b> We constructed the Spatial Planning Map Database (SPMD), an expert-annotated repository characterized by diverse map content and high-quality annotations provided by planning domain specialists.<br> 
                <b>(2)	Framework:</b> We proposed a comprehensive, planning-disciplineâ€“based evaluation standard that measures MLLMsâ€™ planning-map comprehension from four perspectivesâ€”perception, reasoning, association, and applicationâ€”comprising eight fine-grained subcategories.<br> 
                <b>(3)	Experiments:</b> By designing questionâ€“answer tasks grounded in authoritative question banks (specifically, the practice exam questions for the Chinese Registered Urban Planner qualification), we significantly reduced the incidence of hallucinated normative references by the models.<br> 
                <b>(4)	Results:</b> Current state-of-the-art visual large models exhibit significant limitations in the tasks of interpreting and analyzing planning maps. Specifically, these models often fail to accurately recognize the various elements within planning maps and lack the policy-sensitive acuity and professional analytical skills required for planning practice.<br> 
            </p>
            </div>
        </div>
        <div class="lang-zh" style="display: none;">
            <h2 class="title is-3">æ¦‚è¿°</h2>
            <div class="content has-text-justified">
            <p>
                å›½åœŸç©ºé—´è§„åˆ’å›¾æ˜¯å°†å›½åœŸç©ºé—´è§„åˆ’çš„ç†å¿µã€ç›®æ ‡ã€ç­–ç•¥å’Œå…·ä½“æªæ–½ä»¥åœ°å›¾çš„å½¢å¼ç›´è§‚å±•ç¤ºå‡ºæ¥ï¼Œç”¨äºæŒ‡å¯¼å’Œåè°ƒå„ç±»å›½åœŸç©ºé—´å¼€å‘ã€ä¿æŠ¤å’Œåˆ©ç”¨æ´»åŠ¨ã€‚å®ƒä¸ä»…æ˜¯è§„åˆ’å†³ç­–çš„é‡è¦ä¾æ®ï¼Œä¹Ÿæ˜¯å…¬ä¼—å‚ä¸å’Œç›‘ç£è§„åˆ’å®æ–½çš„é‡è¦å·¥å…·ã€‚è§„åˆ’æ˜¯ç»¼åˆæ€§å’Œä¸“ä¸šæ€§æå¼ºçš„å·¥ä½œï¼Œå¦‚æœè¦è¯»é€è§„åˆ’å›¾çº¸ï¼Œä¸ä»…è¦æŠ“ä½ç²¾ç»†çš„å…ƒç´ ï¼ˆç¬¦å·ã€å›¾ä¾‹å’Œåœ°ç†è¦ç´ ç­‰ï¼‰ï¼Œè¿˜è¦æœ‰ç»“åˆæ”¿ç­–è¿›è¡Œç»¼åˆåˆ†æå’Œåˆ¤æ–­çš„èƒ½åŠ›ã€‚è¿™ç§å¤æ‚æ€§ä½¿å¾—è§„åˆ’å›¾çš„ç†è§£å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éšç€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæˆ‘ä»¬å»ºç«‹äº†å›½åœŸç©ºé—´è§„åˆ’å›¾çš„Benchmarkï¼Œä»¥è¯„ä¼°MLLMsåœ¨è§„åˆ’å›¾ç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„è´¡çŒ®å¦‚ä¸‹ï¼š<br>
                <b>(1)	æ•°æ®ï¼š</b> æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¸“å®¶æ ‡æ³¨çš„è§„åˆ’å›¾æ•°æ®åº“Spatial Planning Map Databaseï¼ˆSPMD)ï¼Œå…¶ç‰¹ç‚¹æ˜¯å¤šæ ·åŒ–çš„å›¾åƒå†…å®¹å’Œç”±è§„åˆ’é¢†åŸŸä¸“å®¶æä¾›çš„é«˜è´¨é‡æ ‡æ³¨ã€‚<br>
                <b>(2)	æ¡†æ¶ï¼š</b> æˆ‘ä»¬æå‡ºäº†ä¸€å¥—åŸºäºè§„åˆ’å­¦ç§‘çš„ç»¼åˆæ ‡å‡†ï¼Œä»æ„ŸçŸ¥ã€æ¨ç†ã€å…³è”ã€åº”ç”¨å››ä¸ªè§’åº¦è¡¡é‡MLLMsçš„è§„åˆ’å›¾ç†è§£èƒ½åŠ›ï¼ŒåŒ…æ‹¬8ä¸ªç»†åˆ†ç±»åˆ«ã€‚<br>
                <b>(3)	å®éªŒï¼š</b> é€šè¿‡åŸºäºæƒå¨é¢˜åº“ï¼ˆä¸­å›½æ³¨å†ŒåŸå¸‚è§„åˆ’å¸ˆæ‰§ä¸šèµ„æ ¼è€ƒè¯•å®åŠ¡é¢˜ç›®ï¼‰çŸ¥è¯†æ„å»ºçš„é—®ç­”ä»»åŠ¡ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹â€œå¹»è§‰å¼è§„èŒƒå¼•ç”¨â€çš„æ¯”ä¾‹ã€‚<br>
                <b>(4)	ç»“æœï¼š</b> ç›®å‰çš„SOTAè§†è§‰å¤§æ¨¡å‹ï¼Œåœ¨è§£è¯»å’Œåˆ†æè§„åˆ’å›¾ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„å±€é™æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œè¿™äº›æ¨¡å‹å¸¸å¸¸æ— æ³•å®Œå…¨å‡†ç¡®è¯†åˆ«è§„åˆ’å›¾ä¸­çš„å„ç±»è¦ç´ ï¼Œä¹Ÿç¼ºä¹è§„åˆ’æ‰€éœ€çš„æ”¿ç­–å—…è§‰çµæ•åº¦å’Œä¸“ä¸šåˆ†æèƒ½åŠ›ã€‚<br>
            </p>
            </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 MMIU">
    <span class="MMIU" style="vertical-align: middle">MMIU</span>
  </h1>
  </div>
</section> -->

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="./pictures/image.png" alt="pipeline" class="center">
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  .image-row {
      display: center; /* Use flexbox layout */
  }
  .image-row img {
      width: 40%; /* Each image takes up 50% of the width */
  }
</style>

<div class="container mt-6">
  <div class="content">
    <!-- è‹±æ–‡ç‰ˆï¼ˆé»˜è®¤æ˜¾ç¤ºï¼‰ -->
    <div class="lang-en">
      <h2 class="title is-4">Acknowledgements</h2>
      <p><strong>VQA Data Annotators:</strong> Minxin Chen, Siqi Zha, Yeyang Fu, Chuang Deng, Fenghong An, Hanying Li, Jiayi Fan</p>
      <p><strong>Internal Testers:</strong> Jialu Yu, Yingqi Guo</p>
      <br>
    </div>
    <!-- ä¸­æ–‡ç‰ˆï¼ˆé»˜è®¤éšè—ï¼‰ -->
    <div class="lang-zh" style="display: none;">
      <h2 class="title is-4">è‡´è°¢</h2>
      <p><strong>VQAæ•°æ®æ ‡æ³¨äººå‘˜ï¼š</strong>é™ˆæ—»æ­†ï¼ŒæŸ¥æ€é½ï¼Œä»˜å¶æ‰¬ï¼Œé‚“é—¯ï¼Œå®‰æ«æ³“ï¼Œæç€šæ»¢ï¼ŒèŒƒä½³æŒ¹</p>
      <p><strong>å†…æµ‹äººå‘˜ï¼š</strong>äºä½³ç’ï¼Œéƒ­ç‘›ç¦</p>
      <br>
    </div>
  </div>
</div>

<!-- @PAN TODO: bibtex -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @misc{meng2024mmiumultimodalmultiimageunderstanding,
        title={MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models}, 
        author={Fanqing Meng and Jin Wang and Chuanhao Li and Quanfeng Lu and Hao Tian and Jiaqi Liao and Xizhou Zhu and Jifeng Dai and Yu Qiao and Ping Luo and Kaipeng Zhang and Wenqi Shao},
        year={2024},
        eprint={2408.02718},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2408.02718}, 
  }
</code></pre>
  </div>
</section> -->

<!-- <footer class="footer">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://github.com/OpenGVLab/MMT-Bench">MMT-Bench</a>, <a href="https://mmmu-benchmark.github.io/">MMMU</a>, <a href="https://mathvista.github.io/">MathVista</a> and <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>

</footer> -->

<script>
    function changeLanguage(language) {
        // Hide all language-specific content
        var enContent = document.querySelectorAll('.lang-en');
        var zhContent = document.querySelectorAll('.lang-zh');
        
        if (language === 'en') {
            enContent.forEach(function (el) {
                el.style.display = 'block';
            });
            zhContent.forEach(function (el) {
                el.style.display = 'none';
            });
        } else if (language === 'zh') {
            zhContent.forEach(function (el) {
                el.style.display = 'block';
            });
            enContent.forEach(function (el) {
                el.style.display = 'none';
            });
        }
    }
</script>

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' â†‘';
  }
  .desc::after {
      content: ' â†“';
  }

  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }

  .publication-links .link-block {
    margin: 0 0.5rem;
    display: inline-block;
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* é¼ æ ‡æ‚¬åœæ—¶çš„é˜´å½±æ•ˆæœ */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>
</body>
</html>
